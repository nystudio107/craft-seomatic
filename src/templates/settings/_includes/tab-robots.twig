{% from "seomatic/settings/_includes/macros.twig" import configWarning %}
{% import "_includes/forms" as forms %}

<fieldset>
<div class="flex">
    <div class="flex-grow"></div>
    <a href="{{ seomatic.helper.siteUrl("/robots.txt") }}" class="btn livepreviewbtn" rel="noopener" target="_blank">{{ 'View robots.txt'|t("seomatic") }}</a>
</div>

    {% include "seomatic/settings/_includes/monaco-editor-css.twig" with {baseAssetsUrl: baseAssetsUrl} only %}

    {% namespace "robotsTemplate" %}
    {{ forms.lightswitchField({
        label: "Robots.txt Enabled"|t("seomatic"),
        instructions: "Whether the `robots.txt` template should be rendered"|t("seomatic"),
        id: "include",
        name: "include",
        on: robotsTemplate.include,
        warning: false,
        errors: robotsTemplate.getErrors("include"),
    }) }}

    {{ forms.textAreaField({
        label: "Robots.txt Template"|t("seomatic"),
        instructions: "A `robots.txt` file is a file at the root of your site that indicates those parts of your site you donâ€™t want accessed by search engine crawlers. The file uses the [Robots Exclusion Standard](http://www.robotstxt.org/robotstxt.html), which is a protocol with a small set of commands that can be used to indicate access to your site by section and by specific kinds of web crawlers (such as mobile crawlers vs desktop crawlers)."|t("seomatic"),
        id: "templateString",
        name: "templateString",
        value: robotsTemplate.templateString,
        class: "seomatic-javascript-editor selectize-text",
        warning: false,
        errors: robotsTemplate.getErrors("templateString"),
    }) }}
    {% js %}
        makeMonacoEditor("{{ "templateString"|namespaceInputId }}", "");
    {% endjs %}
{% endnamespace %}
</fieldset>
